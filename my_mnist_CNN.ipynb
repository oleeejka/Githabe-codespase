{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOuOXmBnqJQqhFRk60VTQ/2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oleeejka/Github-codespase/blob/main/my_mnist_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wj8PRP0EwTil"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загружаем набор данных MNIST"
      ],
      "metadata": {
        "id": "7k7qSd5myrRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.MNIST (\n",
        "    root = 'data', ## Указывает директорию, где будет сохранен набор данных.\n",
        "    train = True,\n",
        "    transform = ToTensor(), ## ToTensor() конвертирует PIL изображения или\n",
        "                            ## numpy.ndarray в тензоры PyTorch и нормализует\n",
        "                            ## значения пикселей от 0-255 до 0-1.\n",
        "    download = True ## Если набор данных не найден в указанной директории, он будет автоматически скачан.\n",
        ")\n",
        "\n",
        "test_data = datasets.MNIST (\n",
        "    root = 'data',\n",
        "    train = False,\n",
        "    transform = ToTensor(),\n",
        "    download = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "is1xNDBSxvKJ",
        "outputId": "96055c43-6f1b-44de-8093-da59d0a7984f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 50.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 1.61MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 1.70MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "id": "JG-E65PLzTnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "95em_nY2zH74",
        "outputId": "a9e7ab9b-73fd-44bd-d468-8f498f08021e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset MNIST\n",
              "    Number of datapoints: 10000\n",
              "    Root location: data\n",
              "    Split: Test\n",
              "    StandardTransform\n",
              "Transform: ToTensor()"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data ## выведет датасет"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8_hCmbPzVd9",
        "outputId": "1a282fba-6b24-4e38-9bd4-0f939731bbbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]],\n",
              "\n",
              "        [[0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         ...,\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0],\n",
              "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KtzxylxRzeKP",
        "outputId": "bd87f851-3a06-4675-af42-791144dd4e71"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.data.size() ## size() аналогично shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFjzDzhRzria",
        "outputId": "ea424d1c-3c81-4d15-f703-0ce59df436b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([10000, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.targets.size() ## размер тензора с метками обучающего набора"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yaHvf_OQzw7j",
        "outputId": "63f39d60-528e-41c4-c4b6-481ac263e223"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dataloader**"
      ],
      "metadata": {
        "id": "aCVBBnK80HZR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaders = {\n",
        "    'train': DataLoader(train_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=True,\n",
        "                        num_workers=1), ## num_workers=1: Использует 1 подпроцесс для загрузки данных.\n",
        "                                        ## Это может ускорить загрузку данных, особенно для больших наборов.\n",
        "\n",
        "    'test': DataLoader(test_data,\n",
        "                        batch_size=100,\n",
        "                        shuffle=False,\n",
        "                        num_workers=1),\n",
        "}"
      ],
      "metadata": {
        "id": "gyrLgXdO0KlX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Architecture**"
      ],
      "metadata": {
        "id": "OCzc_iMw1Glr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "    self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "    self.conv2_drop = nn.Dropout2d() ## regularization layer\n",
        "    self.fc1 = nn.Linear(320, 50)\n",
        "    self.fc2 = nn.Linear(50, 10) ## 10 output units for Softmax\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
        "    x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
        "\n",
        "    ## we must flatten the data before fc layers\n",
        "    x = x.view(-1, 320)\n",
        "\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "\n",
        "    return F.softmax(x)\n"
      ],
      "metadata": {
        "id": "UUgDlSVX1JHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**GPU**"
      ],
      "metadata": {
        "id": "FhRy0LF95q9s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "model = CNN().to(device)"
      ],
      "metadata": {
        "id": "GZMoR6ov5rMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Optimizer**"
      ],
      "metadata": {
        "id": "sTm3V_xM5-79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "metadata": {
        "id": "zsIgpNps5_DT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define loss function"
      ],
      "metadata": {
        "id": "VHGohZO16NTu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "EX7Cwg9T6PPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Функция для обучения**"
      ],
      "metadata": {
        "id": "qfe1BvGi6TDp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train(epoch):\n",
        "  model.train() ##  Переводит модель в режим обучения. Это важно, так как некоторые слои\n",
        "                ## (например, Dropout или BatchNorm) ведут себя по-разному в режиме обучения и в режиме оценки.\n",
        "  for batch_idx, (data, target) in enumerate(loaders['train']):\n",
        "    data, target = data.to(device), target.to(device) ##  Перемещает данные и целевые значения на указанное устройство (CPU или GPU).\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data)\n",
        "    loss = loss_fn(output, target)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % 20 == 0:\n",
        "      print(f\"Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders['train'].dataset)} ({100. * batch_idx / len(loaders['train']):.0f}%)]\\t{loss.item():.6f}\")\n",
        "\n",
        "## Эта строка выводит информацию о прогрессе обучения. Разберем ее по частям:\n",
        "## Train Epoch: {epoch} выводит номер текущей эпохи обучения.\n",
        "## [{batch_idx * len(data)}/{len(loaders['train'].dataset)}] показывает, сколько образцов уже обработано в текущей эпохе.\n",
        "## batch_idx * len(data) - количество обработанных образцов (индекс текущего батча умножается на размер батча).\n",
        "## len(loaders['train'].dataset) - общее количество образцов в обучающем наборе данных.\n",
        "## ({100. * batch_idx / len(loaders['train']):.0f}%) Отображает процент завершения текущей эпохи.\n",
        "## batch_idx / len(loaders['train']) - доля обработанных батчей. Умножение на 100 переводит это значение в проценты.\n",
        "## {loss.item():.6f} Выводит значение функции потерь для текущего батча."
      ],
      "metadata": {
        "id": "06oA-RUL6Vuf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing function**"
      ],
      "metadata": {
        "id": "7ptn9tqr9_Hi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Определение функции test(), которая будет оценивать производительность модели на тестовом наборе данных.\n",
        "def test():\n",
        "  model.eval() ## Переводит модель в режим оценки.\n",
        "\n",
        "  test_loss = 0\n",
        "  correct = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for data, target in loaders['test']: ## Начинает цикл по батчам из тестового загрузчика данных.\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      output = model(data)\n",
        "      test_loss += loss_fn(output, target).item() ## Вычисляет потерю для текущего батча и добавляет ее к общей сумме потерь. Метод .item() извлекает скалярное значение из тензора.\n",
        "      pred = output.argmax(dim=1, keepdim=True) ## Получает предсказания модели, выбирая индекс с максимальным значением по измерению 1 (классы). keepdim=True сохраняет размерность тензора.\n",
        "      correct += pred.eq(target.view_as(pred)).sum().item() ## Подсчитывает количество правильных предсказаний:\n",
        "                                                            ##target.view_as(pred) изменяет форму целевого тензора, чтобы она соответствовала форме pred.\n",
        "                                                            ##pred.eq(target.view_as(pred)) создает тензор булевых значений, где True означает правильное предсказание.\n",
        "\n",
        "  test_loss /= len(loaders['test'].dataset)\n",
        "  print(f\"\\nTest set: Average loss: {test_loss:.4f}, Accuracy {correct} / {len(loaders['test'].dataset)}\")\n",
        "## Выводит среднюю потерю на тестовом наборе, test_loss - это сумма потерь для всех батчей, вычисленная в функции test(). И выводит точность модели на тестовом наборе.\n",
        "## Обратите внимание, что здесь предполагается, что test_loss уже разделена на количество батчей или образцов для получения среднего значения."
      ],
      "metadata": {
        "id": "gECI7vTb-CZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, 11):\n",
        "  train(epoch)\n",
        "  test()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5bPd9agSAlBS",
        "outputId": "222be395-3ddf-44d7-b8fe-aa83ea21bfb8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-fafd0c5b4e68>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [0/60000 (0%)]\t2.303187\n",
            "Train Epoch: 1 [2000/60000 (3%)]\t2.265931\n",
            "Train Epoch: 1 [4000/60000 (7%)]\t2.178697\n",
            "Train Epoch: 1 [6000/60000 (10%)]\t2.005345\n",
            "Train Epoch: 1 [8000/60000 (13%)]\t1.925201\n",
            "Train Epoch: 1 [10000/60000 (17%)]\t1.851199\n",
            "Train Epoch: 1 [12000/60000 (20%)]\t1.746310\n",
            "Train Epoch: 1 [14000/60000 (23%)]\t1.773509\n",
            "Train Epoch: 1 [16000/60000 (27%)]\t1.743440\n",
            "Train Epoch: 1 [18000/60000 (30%)]\t1.703995\n",
            "Train Epoch: 1 [20000/60000 (33%)]\t1.714074\n",
            "Train Epoch: 1 [22000/60000 (37%)]\t1.687900\n",
            "Train Epoch: 1 [24000/60000 (40%)]\t1.692217\n",
            "Train Epoch: 1 [26000/60000 (43%)]\t1.712206\n",
            "Train Epoch: 1 [28000/60000 (47%)]\t1.671070\n",
            "Train Epoch: 1 [30000/60000 (50%)]\t1.695120\n",
            "Train Epoch: 1 [32000/60000 (53%)]\t1.597661\n",
            "Train Epoch: 1 [34000/60000 (57%)]\t1.614207\n",
            "Train Epoch: 1 [36000/60000 (60%)]\t1.672397\n",
            "Train Epoch: 1 [38000/60000 (63%)]\t1.662783\n",
            "Train Epoch: 1 [40000/60000 (67%)]\t1.639984\n",
            "Train Epoch: 1 [42000/60000 (70%)]\t1.633377\n",
            "Train Epoch: 1 [44000/60000 (73%)]\t1.608779\n",
            "Train Epoch: 1 [46000/60000 (77%)]\t1.607798\n",
            "Train Epoch: 1 [48000/60000 (80%)]\t1.618633\n",
            "Train Epoch: 1 [50000/60000 (83%)]\t1.622655\n",
            "Train Epoch: 1 [52000/60000 (87%)]\t1.652390\n",
            "Train Epoch: 1 [54000/60000 (90%)]\t1.628644\n",
            "Train Epoch: 1 [56000/60000 (93%)]\t1.619212\n",
            "Train Epoch: 1 [58000/60000 (97%)]\t1.667484\n",
            "\n",
            "Test set: Average loss: 0.0153, Accuracy 9335 / 10000\n",
            "Train Epoch: 2 [0/60000 (0%)]\t1.588601\n",
            "Train Epoch: 2 [2000/60000 (3%)]\t1.604906\n",
            "Train Epoch: 2 [4000/60000 (7%)]\t1.578538\n",
            "Train Epoch: 2 [6000/60000 (10%)]\t1.612931\n",
            "Train Epoch: 2 [8000/60000 (13%)]\t1.595597\n",
            "Train Epoch: 2 [10000/60000 (17%)]\t1.604032\n",
            "Train Epoch: 2 [12000/60000 (20%)]\t1.569060\n",
            "Train Epoch: 2 [14000/60000 (23%)]\t1.618946\n",
            "Train Epoch: 2 [16000/60000 (27%)]\t1.557470\n",
            "Train Epoch: 2 [18000/60000 (30%)]\t1.603293\n",
            "Train Epoch: 2 [20000/60000 (33%)]\t1.564955\n",
            "Train Epoch: 2 [22000/60000 (37%)]\t1.552518\n",
            "Train Epoch: 2 [24000/60000 (40%)]\t1.565143\n",
            "Train Epoch: 2 [26000/60000 (43%)]\t1.599881\n",
            "Train Epoch: 2 [28000/60000 (47%)]\t1.602926\n",
            "Train Epoch: 2 [30000/60000 (50%)]\t1.576138\n",
            "Train Epoch: 2 [32000/60000 (53%)]\t1.559970\n",
            "Train Epoch: 2 [34000/60000 (57%)]\t1.524415\n",
            "Train Epoch: 2 [36000/60000 (60%)]\t1.542872\n",
            "Train Epoch: 2 [38000/60000 (63%)]\t1.540248\n",
            "Train Epoch: 2 [40000/60000 (67%)]\t1.589592\n",
            "Train Epoch: 2 [42000/60000 (70%)]\t1.574003\n",
            "Train Epoch: 2 [44000/60000 (73%)]\t1.528064\n",
            "Train Epoch: 2 [46000/60000 (77%)]\t1.594952\n",
            "Train Epoch: 2 [48000/60000 (80%)]\t1.575067\n",
            "Train Epoch: 2 [50000/60000 (83%)]\t1.543820\n",
            "Train Epoch: 2 [52000/60000 (87%)]\t1.554624\n",
            "Train Epoch: 2 [54000/60000 (90%)]\t1.659916\n",
            "Train Epoch: 2 [56000/60000 (93%)]\t1.529141\n",
            "Train Epoch: 2 [58000/60000 (97%)]\t1.529330\n",
            "\n",
            "Test set: Average loss: 0.0151, Accuracy 9513 / 10000\n",
            "Train Epoch: 3 [0/60000 (0%)]\t1.556196\n",
            "Train Epoch: 3 [2000/60000 (3%)]\t1.607616\n",
            "Train Epoch: 3 [4000/60000 (7%)]\t1.516827\n",
            "Train Epoch: 3 [6000/60000 (10%)]\t1.536802\n",
            "Train Epoch: 3 [8000/60000 (13%)]\t1.572433\n",
            "Train Epoch: 3 [10000/60000 (17%)]\t1.599373\n",
            "Train Epoch: 3 [12000/60000 (20%)]\t1.570277\n",
            "Train Epoch: 3 [14000/60000 (23%)]\t1.551564\n",
            "Train Epoch: 3 [16000/60000 (27%)]\t1.619645\n",
            "Train Epoch: 3 [18000/60000 (30%)]\t1.581344\n",
            "Train Epoch: 3 [20000/60000 (33%)]\t1.531821\n",
            "Train Epoch: 3 [22000/60000 (37%)]\t1.543580\n",
            "Train Epoch: 3 [24000/60000 (40%)]\t1.570614\n",
            "Train Epoch: 3 [26000/60000 (43%)]\t1.522823\n",
            "Train Epoch: 3 [28000/60000 (47%)]\t1.546002\n",
            "Train Epoch: 3 [30000/60000 (50%)]\t1.582415\n",
            "Train Epoch: 3 [32000/60000 (53%)]\t1.568398\n",
            "Train Epoch: 3 [34000/60000 (57%)]\t1.551475\n",
            "Train Epoch: 3 [36000/60000 (60%)]\t1.516761\n",
            "Train Epoch: 3 [38000/60000 (63%)]\t1.586984\n",
            "Train Epoch: 3 [40000/60000 (67%)]\t1.563277\n",
            "Train Epoch: 3 [42000/60000 (70%)]\t1.540313\n",
            "Train Epoch: 3 [44000/60000 (73%)]\t1.498129\n",
            "Train Epoch: 3 [46000/60000 (77%)]\t1.532997\n",
            "Train Epoch: 3 [48000/60000 (80%)]\t1.587556\n",
            "Train Epoch: 3 [50000/60000 (83%)]\t1.528234\n",
            "Train Epoch: 3 [52000/60000 (87%)]\t1.560379\n",
            "Train Epoch: 3 [54000/60000 (90%)]\t1.552437\n",
            "Train Epoch: 3 [56000/60000 (93%)]\t1.546287\n",
            "Train Epoch: 3 [58000/60000 (97%)]\t1.517341\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy 9607 / 10000\n",
            "Train Epoch: 4 [0/60000 (0%)]\t1.546790\n",
            "Train Epoch: 4 [2000/60000 (3%)]\t1.530948\n",
            "Train Epoch: 4 [4000/60000 (7%)]\t1.581848\n",
            "Train Epoch: 4 [6000/60000 (10%)]\t1.492951\n",
            "Train Epoch: 4 [8000/60000 (13%)]\t1.528786\n",
            "Train Epoch: 4 [10000/60000 (17%)]\t1.556070\n",
            "Train Epoch: 4 [12000/60000 (20%)]\t1.538242\n",
            "Train Epoch: 4 [14000/60000 (23%)]\t1.560870\n",
            "Train Epoch: 4 [16000/60000 (27%)]\t1.606728\n",
            "Train Epoch: 4 [18000/60000 (30%)]\t1.498144\n",
            "Train Epoch: 4 [20000/60000 (33%)]\t1.565174\n",
            "Train Epoch: 4 [22000/60000 (37%)]\t1.519562\n",
            "Train Epoch: 4 [24000/60000 (40%)]\t1.572300\n",
            "Train Epoch: 4 [26000/60000 (43%)]\t1.535159\n",
            "Train Epoch: 4 [28000/60000 (47%)]\t1.549922\n",
            "Train Epoch: 4 [30000/60000 (50%)]\t1.556907\n",
            "Train Epoch: 4 [32000/60000 (53%)]\t1.560586\n",
            "Train Epoch: 4 [34000/60000 (57%)]\t1.549199\n",
            "Train Epoch: 4 [36000/60000 (60%)]\t1.543656\n",
            "Train Epoch: 4 [38000/60000 (63%)]\t1.506452\n",
            "Train Epoch: 4 [40000/60000 (67%)]\t1.535565\n",
            "Train Epoch: 4 [42000/60000 (70%)]\t1.560232\n",
            "Train Epoch: 4 [44000/60000 (73%)]\t1.528382\n",
            "Train Epoch: 4 [46000/60000 (77%)]\t1.531853\n",
            "Train Epoch: 4 [48000/60000 (80%)]\t1.523556\n",
            "Train Epoch: 4 [50000/60000 (83%)]\t1.529863\n",
            "Train Epoch: 4 [52000/60000 (87%)]\t1.589908\n",
            "Train Epoch: 4 [54000/60000 (90%)]\t1.553668\n",
            "Train Epoch: 4 [56000/60000 (93%)]\t1.556775\n",
            "Train Epoch: 4 [58000/60000 (97%)]\t1.522500\n",
            "\n",
            "Test set: Average loss: 0.0150, Accuracy 9636 / 10000\n",
            "Train Epoch: 5 [0/60000 (0%)]\t1.536510\n",
            "Train Epoch: 5 [2000/60000 (3%)]\t1.545041\n",
            "Train Epoch: 5 [4000/60000 (7%)]\t1.540562\n",
            "Train Epoch: 5 [6000/60000 (10%)]\t1.581890\n",
            "Train Epoch: 5 [8000/60000 (13%)]\t1.524841\n",
            "Train Epoch: 5 [10000/60000 (17%)]\t1.531417\n",
            "Train Epoch: 5 [12000/60000 (20%)]\t1.555595\n",
            "Train Epoch: 5 [14000/60000 (23%)]\t1.557823\n",
            "Train Epoch: 5 [16000/60000 (27%)]\t1.537008\n",
            "Train Epoch: 5 [18000/60000 (30%)]\t1.577581\n",
            "Train Epoch: 5 [20000/60000 (33%)]\t1.559947\n",
            "Train Epoch: 5 [22000/60000 (37%)]\t1.542496\n",
            "Train Epoch: 5 [24000/60000 (40%)]\t1.506606\n",
            "Train Epoch: 5 [26000/60000 (43%)]\t1.504074\n",
            "Train Epoch: 5 [28000/60000 (47%)]\t1.540878\n",
            "Train Epoch: 5 [30000/60000 (50%)]\t1.536477\n",
            "Train Epoch: 5 [32000/60000 (53%)]\t1.554081\n",
            "Train Epoch: 5 [34000/60000 (57%)]\t1.520551\n",
            "Train Epoch: 5 [36000/60000 (60%)]\t1.519799\n",
            "Train Epoch: 5 [38000/60000 (63%)]\t1.546726\n",
            "Train Epoch: 5 [40000/60000 (67%)]\t1.534090\n",
            "Train Epoch: 5 [42000/60000 (70%)]\t1.587522\n",
            "Train Epoch: 5 [44000/60000 (73%)]\t1.519145\n",
            "Train Epoch: 5 [46000/60000 (77%)]\t1.552361\n",
            "Train Epoch: 5 [48000/60000 (80%)]\t1.536233\n",
            "Train Epoch: 5 [50000/60000 (83%)]\t1.524579\n",
            "Train Epoch: 5 [52000/60000 (87%)]\t1.569331\n",
            "Train Epoch: 5 [54000/60000 (90%)]\t1.557271\n",
            "Train Epoch: 5 [56000/60000 (93%)]\t1.546439\n",
            "Train Epoch: 5 [58000/60000 (97%)]\t1.582044\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy 9679 / 10000\n",
            "Train Epoch: 6 [0/60000 (0%)]\t1.537047\n",
            "Train Epoch: 6 [2000/60000 (3%)]\t1.543485\n",
            "Train Epoch: 6 [4000/60000 (7%)]\t1.536620\n",
            "Train Epoch: 6 [6000/60000 (10%)]\t1.598310\n",
            "Train Epoch: 6 [8000/60000 (13%)]\t1.550586\n",
            "Train Epoch: 6 [10000/60000 (17%)]\t1.492939\n",
            "Train Epoch: 6 [12000/60000 (20%)]\t1.525643\n",
            "Train Epoch: 6 [14000/60000 (23%)]\t1.547866\n",
            "Train Epoch: 6 [16000/60000 (27%)]\t1.548310\n",
            "Train Epoch: 6 [18000/60000 (30%)]\t1.514407\n",
            "Train Epoch: 6 [20000/60000 (33%)]\t1.535233\n",
            "Train Epoch: 6 [22000/60000 (37%)]\t1.552166\n",
            "Train Epoch: 6 [24000/60000 (40%)]\t1.517426\n",
            "Train Epoch: 6 [26000/60000 (43%)]\t1.539735\n",
            "Train Epoch: 6 [28000/60000 (47%)]\t1.502105\n",
            "Train Epoch: 6 [30000/60000 (50%)]\t1.495070\n",
            "Train Epoch: 6 [32000/60000 (53%)]\t1.542461\n",
            "Train Epoch: 6 [34000/60000 (57%)]\t1.541844\n",
            "Train Epoch: 6 [36000/60000 (60%)]\t1.510997\n",
            "Train Epoch: 6 [38000/60000 (63%)]\t1.547940\n",
            "Train Epoch: 6 [40000/60000 (67%)]\t1.545646\n",
            "Train Epoch: 6 [42000/60000 (70%)]\t1.539506\n",
            "Train Epoch: 6 [44000/60000 (73%)]\t1.505520\n",
            "Train Epoch: 6 [46000/60000 (77%)]\t1.545417\n",
            "Train Epoch: 6 [48000/60000 (80%)]\t1.515507\n",
            "Train Epoch: 6 [50000/60000 (83%)]\t1.533758\n",
            "Train Epoch: 6 [52000/60000 (87%)]\t1.508989\n",
            "Train Epoch: 6 [54000/60000 (90%)]\t1.530193\n",
            "Train Epoch: 6 [56000/60000 (93%)]\t1.545008\n",
            "Train Epoch: 6 [58000/60000 (97%)]\t1.562263\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy 9700 / 10000\n",
            "Train Epoch: 7 [0/60000 (0%)]\t1.532589\n",
            "Train Epoch: 7 [2000/60000 (3%)]\t1.557443\n",
            "Train Epoch: 7 [4000/60000 (7%)]\t1.507496\n",
            "Train Epoch: 7 [6000/60000 (10%)]\t1.537035\n",
            "Train Epoch: 7 [8000/60000 (13%)]\t1.519376\n",
            "Train Epoch: 7 [10000/60000 (17%)]\t1.527565\n",
            "Train Epoch: 7 [12000/60000 (20%)]\t1.495257\n",
            "Train Epoch: 7 [14000/60000 (23%)]\t1.526037\n",
            "Train Epoch: 7 [16000/60000 (27%)]\t1.533546\n",
            "Train Epoch: 7 [18000/60000 (30%)]\t1.514420\n",
            "Train Epoch: 7 [20000/60000 (33%)]\t1.476299\n",
            "Train Epoch: 7 [22000/60000 (37%)]\t1.505172\n",
            "Train Epoch: 7 [24000/60000 (40%)]\t1.566921\n",
            "Train Epoch: 7 [26000/60000 (43%)]\t1.530792\n",
            "Train Epoch: 7 [28000/60000 (47%)]\t1.561666\n",
            "Train Epoch: 7 [30000/60000 (50%)]\t1.522150\n",
            "Train Epoch: 7 [32000/60000 (53%)]\t1.557032\n",
            "Train Epoch: 7 [34000/60000 (57%)]\t1.544428\n",
            "Train Epoch: 7 [36000/60000 (60%)]\t1.496491\n",
            "Train Epoch: 7 [38000/60000 (63%)]\t1.540068\n",
            "Train Epoch: 7 [40000/60000 (67%)]\t1.511933\n",
            "Train Epoch: 7 [42000/60000 (70%)]\t1.510548\n",
            "Train Epoch: 7 [44000/60000 (73%)]\t1.511103\n",
            "Train Epoch: 7 [46000/60000 (77%)]\t1.550518\n",
            "Train Epoch: 7 [48000/60000 (80%)]\t1.539956\n",
            "Train Epoch: 7 [50000/60000 (83%)]\t1.510782\n",
            "Train Epoch: 7 [52000/60000 (87%)]\t1.542085\n",
            "Train Epoch: 7 [54000/60000 (90%)]\t1.544658\n",
            "Train Epoch: 7 [56000/60000 (93%)]\t1.506489\n",
            "Train Epoch: 7 [58000/60000 (97%)]\t1.534269\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy 9719 / 10000\n",
            "Train Epoch: 8 [0/60000 (0%)]\t1.524256\n",
            "Train Epoch: 8 [2000/60000 (3%)]\t1.548236\n",
            "Train Epoch: 8 [4000/60000 (7%)]\t1.562589\n",
            "Train Epoch: 8 [6000/60000 (10%)]\t1.530732\n",
            "Train Epoch: 8 [8000/60000 (13%)]\t1.520429\n",
            "Train Epoch: 8 [10000/60000 (17%)]\t1.540408\n",
            "Train Epoch: 8 [12000/60000 (20%)]\t1.526336\n",
            "Train Epoch: 8 [14000/60000 (23%)]\t1.547233\n",
            "Train Epoch: 8 [16000/60000 (27%)]\t1.533917\n",
            "Train Epoch: 8 [18000/60000 (30%)]\t1.535788\n",
            "Train Epoch: 8 [20000/60000 (33%)]\t1.516655\n",
            "Train Epoch: 8 [22000/60000 (37%)]\t1.528113\n",
            "Train Epoch: 8 [24000/60000 (40%)]\t1.539844\n",
            "Train Epoch: 8 [26000/60000 (43%)]\t1.522133\n",
            "Train Epoch: 8 [28000/60000 (47%)]\t1.508123\n",
            "Train Epoch: 8 [30000/60000 (50%)]\t1.495284\n",
            "Train Epoch: 8 [32000/60000 (53%)]\t1.522217\n",
            "Train Epoch: 8 [34000/60000 (57%)]\t1.502674\n",
            "Train Epoch: 8 [36000/60000 (60%)]\t1.505750\n",
            "Train Epoch: 8 [38000/60000 (63%)]\t1.541283\n",
            "Train Epoch: 8 [40000/60000 (67%)]\t1.554727\n",
            "Train Epoch: 8 [42000/60000 (70%)]\t1.557233\n",
            "Train Epoch: 8 [44000/60000 (73%)]\t1.520625\n",
            "Train Epoch: 8 [46000/60000 (77%)]\t1.498464\n",
            "Train Epoch: 8 [48000/60000 (80%)]\t1.526969\n",
            "Train Epoch: 8 [50000/60000 (83%)]\t1.510910\n",
            "Train Epoch: 8 [52000/60000 (87%)]\t1.539166\n",
            "Train Epoch: 8 [54000/60000 (90%)]\t1.540604\n",
            "Train Epoch: 8 [56000/60000 (93%)]\t1.523948\n",
            "Train Epoch: 8 [58000/60000 (97%)]\t1.516876\n",
            "\n",
            "Test set: Average loss: 0.0149, Accuracy 9746 / 10000\n",
            "Train Epoch: 9 [0/60000 (0%)]\t1.535647\n",
            "Train Epoch: 9 [2000/60000 (3%)]\t1.519064\n",
            "Train Epoch: 9 [4000/60000 (7%)]\t1.517192\n",
            "Train Epoch: 9 [6000/60000 (10%)]\t1.547442\n",
            "Train Epoch: 9 [8000/60000 (13%)]\t1.514354\n",
            "Train Epoch: 9 [10000/60000 (17%)]\t1.527756\n",
            "Train Epoch: 9 [12000/60000 (20%)]\t1.522816\n",
            "Train Epoch: 9 [14000/60000 (23%)]\t1.498156\n",
            "Train Epoch: 9 [16000/60000 (27%)]\t1.503376\n",
            "Train Epoch: 9 [18000/60000 (30%)]\t1.509064\n",
            "Train Epoch: 9 [20000/60000 (33%)]\t1.547793\n",
            "Train Epoch: 9 [22000/60000 (37%)]\t1.514975\n",
            "Train Epoch: 9 [24000/60000 (40%)]\t1.497548\n",
            "Train Epoch: 9 [26000/60000 (43%)]\t1.508630\n",
            "Train Epoch: 9 [28000/60000 (47%)]\t1.543596\n",
            "Train Epoch: 9 [30000/60000 (50%)]\t1.526266\n",
            "Train Epoch: 9 [32000/60000 (53%)]\t1.520739\n",
            "Train Epoch: 9 [34000/60000 (57%)]\t1.542238\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-7e22a22646fe>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m11\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-25-88f4f899bf32>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-fafd0c5b4e68>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_drop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;31m## we must flatten the data before fc layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    547\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             )\n\u001b[0;32m--> 549\u001b[0;31m         return F.conv2d(\n\u001b[0m\u001b[1;32m    550\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdilation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroups\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         )\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Визуализация"
      ],
      "metadata": {
        "id": "zcg5tqA4BL03"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Этот код делает следующее:\n",
        "\n",
        "    ## Берет первое изображение из тестового набора.\n",
        "    ## Пропускает его через обученную модель для получения предсказания.\n",
        "    ## Выводит предсказанный класс (цифру).\n",
        "    ## Отображает само изображение.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "model.eval() # переводит модель в режим оценки.\n",
        "\n",
        "data, target = test_data[0] ##  Извлекает первый образец и его метку из тестового набора данных.\n",
        "\n",
        "data = data.unsqueeze(0).to(device) ## unsqueeze(0) добавляет размерность батча (превращает [1, 28, 28] в [1, 1, 28, 28]).\n",
        "\n",
        "output = model(data)\n",
        "\n",
        "prediction = output.argmax(dim=1, keepdim=True).item() ## argmax(dim=1) находит индекс максимального значения (предсказанный класс).\n",
        "\n",
        "print(f'Prediction: {prediction}') ## Выводит предсказанный класс (цифру).\n",
        "\n",
        "image = data.squeeze(0).squeeze(0).cpu().numpy() ## squeeze(0) удаляет размерности батча и канала.\n",
        "                                                 ## cpu() перемещает данные обратно на CPU (если они были на GPU).\n",
        "                                                 ## numpy() преобразует тензор PyTorch в массив NumPy.\n",
        "\n",
        "\n",
        "plt.imshow(image, cmap='gray') # imshow() отображает изображение.\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "_CXvvtBzBKf_",
        "outputId": "bce5c866-39ea-476e-c20c-e717fd8a2965"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-fafd0c5b4e68>:23: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  return F.softmax(x)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction: 7\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGdCAYAAABU0qcqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaqElEQVR4nO3df2xV9f3H8VeL9ILaXiylvb2jQEEFwy8ng9rwYygNtC4GtEtA/QMWAoFdzLDzx7qIKFvSjSWOuCD+s8BMxF+JQCRLMym2hNliqDDCph3tugGBFsVxbylSGP18/yDer1cKeMq9ffdeno/kJPTe8+l9ezzhyWlvT9Occ04AAPSxdOsBAAA3JwIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBM3GI9wLd1d3frxIkTyszMVFpamvU4AACPnHPq6OhQMBhUevrVr3P6XYBOnDihgoIC6zEAADfo2LFjGj58+FWf73dfgsvMzLQeAQAQB9f7+zxhAdq4caNGjRqlQYMGqaioSB9//PF3WseX3QAgNVzv7/OEBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUqUS8HAAgGbkEmDZtmguFQtGPL1265ILBoKuqqrru2nA47CSxsbGxsSX5Fg6Hr/n3fdyvgC5cuKDGxkaVlJREH0tPT1dJSYnq6+uv2L+rq0uRSCRmAwCkvrgH6IsvvtClS5eUl5cX83heXp7a2tqu2L+qqkp+vz+68Q44ALg5mL8LrrKyUuFwOLodO3bMeiQAQB+I+88B5eTkaMCAAWpvb495vL29XYFA4Ir9fT6ffD5fvMcAAPRzcb8CysjI0JQpU1RTUxN9rLu7WzU1NSouLo73ywEAklRC7oRQUVGhxYsX6wc/+IGmTZumDRs2qLOzUz/5yU8S8XIAgCSUkAAtXLhQn3/+uV544QW1tbXp3nvvVXV19RVvTAAA3LzSnHPOeohvikQi8vv91mMAAG5QOBxWVlbWVZ83fxccAODmRIAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATMQ9QC+++KLS0tJitnHjxsX7ZQAASe6WRHzS8ePHa9euXf//Irck5GUAAEksIWW45ZZbFAgEEvGpAQApIiHfAzpy5IiCwaBGjx6tJ554QkePHr3qvl1dXYpEIjEbACD1xT1ARUVF2rJli6qrq7Vp0ya1trZq5syZ6ujo6HH/qqoq+f3+6FZQUBDvkQAA/VCac84l8gXOnDmjkSNH6uWXX9bSpUuveL6rq0tdXV3RjyORCBECgBQQDoeVlZV11ecT/u6AIUOG6O6771Zzc3OPz/t8Pvl8vkSPAQDoZxL+c0Bnz55VS0uL8vPzE/1SAIAkEvcAPf3006qrq9O///1vffTRR3rkkUc0YMAAPfbYY/F+KQBAEov7l+COHz+uxx57TKdPn9awYcM0Y8YMNTQ0aNiwYfF+KQBAEkv4mxC8ikQi8vv91mMAAG7Q9d6EwL3gAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATCf+FdOhbP/7xjz2vWbZsWa9e68SJE57XnD9/3vOaN954w/OatrY2z2skXfUXJwKIP66AAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYCLNOeesh/imSCQiv99vPUbS+te//uV5zahRo+I/iLGOjo5erfv73/8e50kQb8ePH/e8Zv369b16rf379/dqHS4Lh8PKysq66vNcAQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJm6xHgDxtWzZMs9rJk2a1KvX+vTTTz2vueeeezyvue+++zyvmT17tuc1knT//fd7XnPs2DHPawoKCjyv6Uv/+9//PK/5/PPPPa/Jz8/3vKY3jh492qt13Iw0sbgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDPSFFNTU9Mna3qrurq6T17njjvu6NW6e++91/OaxsZGz2umTp3qeU1fOn/+vOc1//znPz2v6c0NbbOzsz2vaWlp8bwGiccVEADABAECAJjwHKA9e/bo4YcfVjAYVFpamrZv3x7zvHNOL7zwgvLz8zV48GCVlJToyJEj8ZoXAJAiPAeos7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b968Xn1NGQCQujy/CaGsrExlZWU9Puec04YNG/T8889r/vz5kqTXX39deXl52r59uxYtWnRj0wIAUkZcvwfU2tqqtrY2lZSURB/z+/0qKipSfX19j2u6uroUiURiNgBA6otrgNra2iRJeXl5MY/n5eVFn/u2qqoq+f3+6FZQUBDPkQAA/ZT5u+AqKysVDoej27Fjx6xHAgD0gbgGKBAISJLa29tjHm9vb48+920+n09ZWVkxGwAg9cU1QIWFhQoEAjE/WR+JRLRv3z4VFxfH86UAAEnO87vgzp49q+bm5ujHra2tOnjwoLKzszVixAitXr1av/71r3XXXXepsLBQa9asUTAY1IIFC+I5NwAgyXkO0P79+/XAAw9EP66oqJAkLV68WFu2bNGzzz6rzs5OLV++XGfOnNGMGTNUXV2tQYMGxW9qAEDSS3POOeshvikSicjv91uPAcCj8vJyz2veeecdz2sOHz7sec03/9HsxZdfftmrdbgsHA5f8/v65u+CAwDcnAgQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGDC869jAJD6cnNzPa959dVXPa9JT/f+b+B169Z5XsNdrfsnroAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABPcjBTAFUKhkOc1w4YN87zmv//9r+c1TU1Nntegf+IKCABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwwc1IgRQ2ffr0Xq37xS9+EedJerZgwQLPaw4fPhz/QWCCKyAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQ3IwVS2EMPPdSrdQMHDvS8pqamxvOa+vp6z2uQOrgCAgCYIEAAABOeA7Rnzx49/PDDCgaDSktL0/bt22OeX7JkidLS0mK20tLSeM0LAEgRngPU2dmpyZMna+PGjVfdp7S0VCdPnoxub7755g0NCQBIPZ7fhFBWVqaysrJr7uPz+RQIBHo9FAAg9SXke0C1tbXKzc3V2LFjtXLlSp0+ffqq+3Z1dSkSicRsAIDUF/cAlZaW6vXXX1dNTY1++9vfqq6uTmVlZbp06VKP+1dVVcnv90e3goKCeI8EAOiH4v5zQIsWLYr+eeLEiZo0aZLGjBmj2tpazZkz54r9KysrVVFREf04EokQIQC4CST8bdijR49WTk6Ompube3ze5/MpKysrZgMApL6EB+j48eM6ffq08vPzE/1SAIAk4vlLcGfPno25mmltbdXBgweVnZ2t7OxsvfTSSyovL1cgEFBLS4ueffZZ3XnnnZo3b15cBwcAJDfPAdq/f78eeOCB6Mdff/9m8eLF2rRpkw4dOqQ//elPOnPmjILBoObOnatf/epX8vl88ZsaAJD00pxzznqIb4pEIvL7/dZjAP3O4MGDPa/Zu3dvr15r/Pjxntc8+OCDntd89NFHntcgeYTD4Wt+X597wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBE3H8lN4DEeOaZZzyv+f73v9+r16qurva8hjtbwyuugAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAE9yMFDDwox/9yPOaNWvWeF4TiUQ8r5GkdevW9Wod4AVXQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACW5GCtygoUOHel7zyiuveF4zYMAAz2v+/Oc/e14jSQ0NDb1aB3jBFRAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIKbkQLf0JsbflZXV3teU1hY6HlNS0uL5zVr1qzxvAboK1wBAQBMECAAgAlPAaqqqtLUqVOVmZmp3NxcLViwQE1NTTH7nD9/XqFQSEOHDtXtt9+u8vJytbe3x3VoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2Rvd56qmn9P777+vdd99VXV2dTpw4oUcffTTugwMAkpunNyF8+5utW7ZsUW5urhobGzVr1iyFw2H98Y9/1NatW/Xggw9KkjZv3qx77rlHDQ0Nuv/+++M3OQAgqd3Q94DC4bAkKTs7W5LU2NioixcvqqSkJLrPuHHjNGLECNXX1/f4Obq6uhSJRGI2AEDq63WAuru7tXr1ak2fPl0TJkyQJLW1tSkjI0NDhgyJ2TcvL09tbW09fp6qqir5/f7oVlBQ0NuRAABJpNcBCoVCOnz4sN56660bGqCyslLhcDi6HTt27IY+HwAgOfTqB1FXrVqlnTt3as+ePRo+fHj08UAgoAsXLujMmTMxV0Ht7e0KBAI9fi6fzyefz9ebMQAASczTFZBzTqtWrdK2bdu0e/fuK36ae8qUKRo4cKBqamqijzU1Neno0aMqLi6Oz8QAgJTg6QooFApp69at2rFjhzIzM6Pf1/H7/Ro8eLD8fr+WLl2qiooKZWdnKysrS08++aSKi4t5BxwAIIanAG3atEmSNHv27JjHN2/erCVLlkiSfv/73ys9PV3l5eXq6urSvHnz9Oqrr8ZlWABA6khzzjnrIb4pEonI7/dbj4Gb1N133+15zWeffZaASa40f/58z2vef//9BEwCfDfhcFhZWVlXfZ57wQEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMBEr34jKtDfjRw5slfr/vKXv8R5kp4988wzntfs3LkzAZMAdrgCAgCYIEAAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMcDNSpKTly5f3at2IESPiPEnP6urqPK9xziVgEsAOV0AAABMECABgggABAEwQIACACQIEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAluRop+b8aMGZ7XPPnkkwmYBEA8cQUEADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJjgZqTo92bOnOl5ze23356ASXrW0tLiec3Zs2cTMAmQXLgCAgCYIEAAABOeAlRVVaWpU6cqMzNTubm5WrBggZqammL2mT17ttLS0mK2FStWxHVoAEDy8xSguro6hUIhNTQ06IMPPtDFixc1d+5cdXZ2xuy3bNkynTx5MrqtX78+rkMDAJKfpzchVFdXx3y8ZcsW5ebmqrGxUbNmzYo+fuuttyoQCMRnQgBASrqh7wGFw2FJUnZ2dszjb7zxhnJycjRhwgRVVlbq3LlzV/0cXV1dikQiMRsAIPX1+m3Y3d3dWr16taZPn64JEyZEH3/88cc1cuRIBYNBHTp0SM8995yampr03nvv9fh5qqqq9NJLL/V2DABAkup1gEKhkA4fPqy9e/fGPL58+fLonydOnKj8/HzNmTNHLS0tGjNmzBWfp7KyUhUVFdGPI5GICgoKejsWACBJ9CpAq1at0s6dO7Vnzx4NHz78mvsWFRVJkpqbm3sMkM/nk8/n680YAIAk5ilAzjk9+eST2rZtm2pra1VYWHjdNQcPHpQk5efn92pAAEBq8hSgUCikrVu3aseOHcrMzFRbW5skye/3a/DgwWppadHWrVv10EMPaejQoTp06JCeeuopzZo1S5MmTUrIfwAAIDl5CtCmTZskXf5h02/avHmzlixZooyMDO3atUsbNmxQZ2enCgoKVF5erueffz5uAwMAUoPnL8FdS0FBgerq6m5oIADAzYG7YQPf8Le//c3zmjlz5nhe8+WXX3peA6QabkYKADBBgAAAJggQAMAEAQIAmCBAAAATBAgAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJhIc9e7xXUfi0Qi8vv91mMAAG5QOBxWVlbWVZ/nCggAYIIAAQBMECAAgAkCBAAwQYAAACYIEADABAECAJggQAAAEwQIAGCCAAEATBAgAICJfhegfnZrOgBAL13v7/N+F6COjg7rEQAAcXC9v8/73d2wu7u7deLECWVmZiotLS3muUgkooKCAh07duyad1hNdRyHyzgOl3EcLuM4XNYfjoNzTh0dHQoGg0pPv/p1zi19ONN3kp6eruHDh19zn6ysrJv6BPsax+EyjsNlHIfLOA6XWR+H7/Jrdfrdl+AAADcHAgQAMJFUAfL5fFq7dq18Pp/1KKY4DpdxHC7jOFzGcbgsmY5Dv3sTAgDg5pBUV0AAgNRBgAAAJggQAMAEAQIAmEiaAG3cuFGjRo3SoEGDVFRUpI8//th6pD734osvKi0tLWYbN26c9VgJt2fPHj388MMKBoNKS0vT9u3bY553zumFF15Qfn6+Bg8erJKSEh05csRm2AS63nFYsmTJFedHaWmpzbAJUlVVpalTpyozM1O5ublasGCBmpqaYvY5f/68QqGQhg4dqttvv13l5eVqb283mjgxvstxmD179hXnw4oVK4wm7llSBOjtt99WRUWF1q5dq08++USTJ0/WvHnzdOrUKevR+tz48eN18uTJ6LZ3717rkRKus7NTkydP1saNG3t8fv369XrllVf02muvad++fbrttts0b948nT9/vo8nTazrHQdJKi0tjTk/3nzzzT6cMPHq6uoUCoXU0NCgDz74QBcvXtTcuXPV2dkZ3eepp57S+++/r3fffVd1dXU6ceKEHn30UcOp4++7HAdJWrZsWcz5sH79eqOJr8IlgWnTprlQKBT9+NKlSy4YDLqqqirDqfre2rVr3eTJk63HMCXJbdu2Lfpxd3e3CwQC7ne/+130sTNnzjifz+fefPNNgwn7xrePg3POLV682M2fP99kHiunTp1yklxdXZ1z7vL/+4EDB7p33303us+nn37qJLn6+nqrMRPu28fBOed++MMfup/97Gd2Q30H/f4K6MKFC2psbFRJSUn0sfT0dJWUlKi+vt5wMhtHjhxRMBjU6NGj9cQTT+jo0aPWI5lqbW1VW1tbzPnh9/tVVFR0U54ftbW1ys3N1dixY7Vy5UqdPn3aeqSECofDkqTs7GxJUmNjoy5evBhzPowbN04jRoxI6fPh28fha2+88YZycnI0YcIEVVZW6ty5cxbjXVW/uxnpt33xxRe6dOmS8vLyYh7Py8vTZ599ZjSVjaKiIm3ZskVjx47VyZMn9dJLL2nmzJk6fPiwMjMzrccz0dbWJkk9nh9fP3ezKC0t1aOPPqrCwkK1tLTol7/8pcrKylRfX68BAwZYjxd33d3dWr16taZPn64JEyZIunw+ZGRkaMiQITH7pvL50NNxkKTHH39cI0eOVDAY1KFDh/Tcc8+pqalJ7733nuG0sfp9gPD/ysrKon+eNGmSioqKNHLkSL3zzjtaunSp4WToDxYtWhT988SJEzVp0iSNGTNGtbW1mjNnjuFkiREKhXT48OGb4vug13K147B8+fLonydOnKj8/HzNmTNHLS0tGjNmTF+P2aN+/yW4nJwcDRgw4Ip3sbS3tysQCBhN1T8MGTJEd999t5qbm61HMfP1OcD5caXRo0crJycnJc+PVatWaefOnfrwww9jfn1LIBDQhQsXdObMmZj9U/V8uNpx6ElRUZEk9avzod8HKCMjQ1OmTFFNTU30se7ubtXU1Ki4uNhwMntnz55VS0uL8vPzrUcxU1hYqEAgEHN+RCIR7du376Y/P44fP67Tp0+n1PnhnNOqVau0bds27d69W4WFhTHPT5kyRQMHDow5H5qamnT06NGUOh+udxx6cvDgQUnqX+eD9bsgvou33nrL+Xw+t2XLFvePf/zDLV++3A0ZMsS1tbVZj9anfv7zn7va2lrX2trq/vrXv7qSkhKXk5PjTp06ZT1aQnV0dLgDBw64AwcOOEnu5ZdfdgcOHHD/+c9/nHPO/eY3v3FDhgxxO3bscIcOHXLz5893hYWF7quvvjKePL6udRw6Ojrc008/7err611ra6vbtWuXu++++9xdd93lzp8/bz163KxcudL5/X5XW1vrTp48Gd3OnTsX3WfFihVuxIgRbvfu3W7//v2uuLjYFRcXG04df9c7Ds3NzW7dunVu//79rrW11e3YscONHj3azZo1y3jyWEkRIOec+8Mf/uBGjBjhMjIy3LRp01xDQ4P1SH1u4cKFLj8/32VkZLjvfe97buHCha65udl6rIT78MMPnaQrtsWLFzvnLr8Ve82aNS4vL8/5fD43Z84c19TUZDt0AlzrOJw7d87NnTvXDRs2zA0cONCNHDnSLVu2LOX+kdbTf78kt3nz5ug+X331lfvpT3/q7rjjDnfrrbe6Rx55xJ08edJu6AS43nE4evSomzVrlsvOznY+n8/deeed7plnnnHhcNh28G/h1zEAAEz0++8BAQBSEwECAJggQAAAEwQIAGCCAAEATBAgAIAJAgQAMEGAAAAmCBAAwAQBAgCYIEAAABMECABg4v8AjVqFRqQZEfIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}